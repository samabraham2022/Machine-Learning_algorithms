{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB ASSESSMENT - 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAM ABRAHAM JOSHY \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20BCE0986"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB L43+L44"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAM ABRAHAM JOSHY \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a program to implement k-Nearest Neighbour algorithm to classify the iris data set.\n",
    "Print both correct and wrong predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9666666666666667\n",
      "Correct predictions:\n",
      "Sample  1 :  virginica\n",
      "Sample  2 :  versicolor\n",
      "Sample  3 :  setosa\n",
      "Sample  4 :  virginica\n",
      "Sample  5 :  setosa\n",
      "Sample  6 :  virginica\n",
      "Sample  7 :  setosa\n",
      "Sample  8 :  versicolor\n",
      "Sample  9 :  versicolor\n",
      "Sample  10 :  versicolor\n",
      "Sample  11 :  virginica\n",
      "Sample  12 :  versicolor\n",
      "Sample  13 :  versicolor\n",
      "Sample  14 :  versicolor\n",
      "Sample  16 :  setosa\n",
      "Sample  17 :  versicolor\n",
      "Sample  18 :  versicolor\n",
      "Sample  19 :  setosa\n",
      "Sample  20 :  setosa\n",
      "Sample  21 :  virginica\n",
      "Sample  22 :  versicolor\n",
      "Sample  23 :  setosa\n",
      "Sample  24 :  setosa\n",
      "Sample  25 :  virginica\n",
      "Sample  26 :  setosa\n",
      "Sample  27 :  setosa\n",
      "Sample  28 :  versicolor\n",
      "Sample  29 :  versicolor\n",
      "Sample  30 :  setosa\n",
      "Wrong predictions:\n",
      "Sample  15 : predicted  virginica , actual  versicolor\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"Correct predictions:\")\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        print(\"Sample \", i+1, \": \", iris.target_names[y_pred[i]])\n",
    "print(\"Wrong predictions:\")\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        print(\"Sample \", i+1, \": predicted \", iris.target_names[y_pred[i]], \", actual \", iris.target_names[y_test[i]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train SVM classifier using sklearn digits dataset( i.e from sklearn datasets import load_digits)\n",
    "and then\n",
    "a. Measure accuracy of your model using different kernels such as rbf and linear.\n",
    "b. Tune your model further using regularization and gamma parameters and try to\n",
    "come up highest accuracy score.\n",
    "c. Use 80% of samples as training data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (linear kernel):  0.9777777777777777\n",
      "Accuracy (rbf kernel):  0.9861111111111112\n",
      "Accuracy (Tuned):  0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (linear kernel): \", accuracy)\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (rbf kernel): \", accuracy)\n",
    "clf = svm.SVC(C=1,kernel='rbf',degree=3,gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (Tuned): \", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build an Artificial Neural Network by implementing the Back propagation algorithm and test\n",
    "the same using appropriate data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01519504]\n",
      " [0.98007138]\n",
      " [0.97363897]\n",
      " [0.02619722]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1], 4) \n",
    "        self.weights2 = np.random.rand(4, 1)                 \n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        return self.output\n",
    "    def backprop(self):\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "nn = NeuralNetwork(X,y)\n",
    "\n",
    "for i in range(1500):\n",
    "    nn.feedforward()\n",
    "    nn.backprop()\n",
    "\n",
    "print(nn.output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bagging Ensembles including Bagged Decision Trees, Random Forest and Extra\n",
    "Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "X = data.drop(\" buys_computer\", axis=1)\n",
    "y = data[\" buys_computer\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    random_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Boosting Ensembles including AdaBoost and Stochastic Gradient Boosting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "X = df.drop(\" buys_computer\", axis=1)\n",
    "y = df[\" buys_computer\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=1)\n",
    "model = AdaBoostClassifier(base_estimator=dt, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Voting Ensembles for averaging the predictions for any arbitrary models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=1)\n",
    "clf3 = SVC(probability=True, random_state=1)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('svc', clf3)], voting='soft')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test data: {:.2f}%\".format(ensemble.score(X_test, y_test) * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ed999c28bc32721ac51a38ca1a57016e41ebd3526a013e738b73c17d9f87e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
